/**
 * Servi√ßo de Processamento de √Åudio em Tempo Real
 * Pipeline completo para captura, processamento e an√°lise de √°udio
 */

import { chordDetectionAIService, ChordClassificationResult } from './ChordDetectionAIService';

export interface AudioProcessingConfig {
  sampleRate: number;
  bufferSize: number;
  channels: number;
  echoCancellation: boolean;
  noiseSuppression: boolean;
  autoGainControl: boolean;
}

export interface ProcessedAudioChunk {
  audioData: Float32Array;
  timestamp: number;
  duration: number;
  rms: number;
  peak: number;
  isSilent: boolean;
}

export interface AudioAnalysisResult {
  chunk: ProcessedAudioChunk;
  chordDetection?: ChordClassificationResult;
  quality: {
    signalToNoiseRatio: number;
    clarity: number;
    stability: number;
  };
}

export class AudioProcessingService {
  private static instance: AudioProcessingService;
  private audioContext: AudioContext | null = null;
  private microphone: MediaStreamAudioSourceNode | null = null;
  private analyser: AnalyserNode | null = null;
  private processor: ScriptProcessorNode | null = null;
  private stream: MediaStream | null = null;

  private isInitialized = false;
  private isProcessing = false;
  private onAudioChunkCallback: ((result: AudioAnalysisResult) => void) | null = null;

  // Buffers para an√°lise
  private audioBuffer: Float32Array;
  private circularBuffer: Float32Array;
  private bufferIndex = 0;
  private recentChunks: Float32Array[] = []; // √öltimos 3 chunks para an√°lise acumulada
  private maxRecentChunks = 3;

  // Configura√ß√µes padr√£o (otimizadas para baixa lat√™ncia)
  private config: AudioProcessingConfig = {
    sampleRate: 44100,
    bufferSize: 1024, // ~23ms de √°udio a 44.1kHz (reduzido para menor lat√™ncia)
    channels: 1,
    echoCancellation: true,
    noiseSuppression: true,
    autoGainControl: true
  };

  // Estat√≠sticas de processamento
  private stats = {
    chunksProcessed: 0,
    averageLatency: 0,
    droppedFrames: 0,
    lastProcessingTime: 0
  };

  private constructor() {
    this.audioBuffer = new Float32Array(this.config.bufferSize);
    this.circularBuffer = new Float32Array(this.config.bufferSize * 4); // Buffer circular 4x maior
  }

  static getInstance(): AudioProcessingService {
    if (!AudioProcessingService.instance) {
      AudioProcessingService.instance = new AudioProcessingService();
    }
    return AudioProcessingService.instance;
  }

  /**
   * Inicializa o servi√ßo de processamento de √°udio
   */
  async initialize(config?: Partial<AudioProcessingConfig>): Promise<boolean> {
    if (this.isInitialized) return true;

    try {
      console.log('üéµ Inicializando processamento de √°udio...');

      // Atualizar configura√ß√µes
      if (config) {
        this.config = { ...this.config, ...config };
        this.audioBuffer = new Float32Array(this.config.bufferSize);
        this.circularBuffer = new Float32Array(this.config.bufferSize * 4);
      }

      // Solicitar acesso ao microfone
      this.stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: this.config.sampleRate,
          channelCount: this.config.channels,
          echoCancellation: this.config.echoCancellation,
          noiseSuppression: this.config.noiseSuppression,
          autoGainControl: this.config.autoGainControl
        }
      });

      // Criar contexto de √°udio (otimizado para baixa lat√™ncia)
      this.audioContext = new AudioContext({
        sampleRate: this.config.sampleRate,
        latencyHint: 'interactive' // Baixa lat√™ncia
      });
      
      // Otimizar para processamento em tempo real
      if (this.audioContext.state === 'suspended') {
        await this.audioContext.resume();
      }

      // Criar n√≥s de √°udio
      this.microphone = this.audioContext.createMediaStreamSource(this.stream);
      this.analyser = this.audioContext.createAnalyser();

      // Configurar analyser (otimizado para baixa lat√™ncia)
      this.analyser.fftSize = this.config.bufferSize * 2;
      this.analyser.smoothingTimeConstant = 0.3; // Aumentado para suavizar varia√ß√µes
      this.analyser.minDecibels = -90;
      this.analyser.maxDecibels = -10;

      // Criar processor para processamento em tempo real
      this.processor = this.audioContext.createScriptProcessor(
        this.config.bufferSize,
        this.config.channels,
        this.config.channels
      );

      // Conectar n√≥s
      this.microphone.connect(this.analyser);
      this.microphone.connect(this.processor);
      this.processor.connect(this.audioContext.destination);

      // Configurar callback de processamento
      this.processor.onaudioprocess = this.handleAudioProcess.bind(this);

      // Inicializar servi√ßo de IA para detec√ß√£o de acordes
      await chordDetectionAIService.initialize();

      this.isInitialized = true;
      console.log('‚úÖ Processamento de √°udio inicializado');

      return true;
    } catch (error) {
      console.error('‚ùå Erro ao inicializar processamento de √°udio:', error);
      this.dispose();
      return false;
    }
  }

  /**
   * Inicia processamento de √°udio em tempo real
   */
  startProcessing(callback: (result: AudioAnalysisResult) => void): void {
    if (!this.isInitialized) {
      throw new Error('Servi√ßo n√£o inicializado. Chame initialize() primeiro.');
    }

    this.onAudioChunkCallback = callback;
    this.isProcessing = true;
    this.resetStats();

    console.log('‚ñ∂Ô∏è Processamento de √°udio iniciado');
  }

  /**
   * Para processamento de √°udio
   */
  stopProcessing(): void {
    this.isProcessing = false;
    this.onAudioChunkCallback = null;
    console.log('‚èπÔ∏è Processamento de √°udio parado');
  }

  /**
   * Callback principal de processamento de √°udio
   */
  private async handleAudioProcess(event: AudioProcessingEvent): Promise<void> {
    if (!this.isProcessing) return;

    const startTime = performance.now();

    try {
      // Obter dados do canal esquerdo (mono)
      const inputBuffer = event.inputBuffer.getChannelData(0);

      // Criar chunk processado
      const chunk = this.processAudioChunk(inputBuffer);

      // Analisar qualidade do sinal
      const quality = this.analyzeSignalQuality(chunk);

      // Detec√ß√£o de acordes com IA (otimizada)
      let chordDetection: ChordClassificationResult | undefined;
      
      // Filtro mais inteligente: s√≥ detectar se h√° sinal significativo
      const hasSignificantSignal = chunk.rms > 0.02 && chunk.peak > 0.05 && !chunk.isSilent;
      
      if (hasSignificantSignal) {
        try {
          // Usar buffer acumulado para melhor an√°lise (√∫ltimos 3 chunks)
          const accumulatedBuffer = this.getAccumulatedBuffer();
          
          // Detectar apenas se o buffer acumulado tem dura√ß√£o suficiente (~70ms)
          if (accumulatedBuffer.length >= this.config.bufferSize * 3) {
            chordDetection = await chordDetectionAIService.detectChord(accumulatedBuffer);
          }
        } catch (error) {
          console.warn('Erro na detec√ß√£o de acordes:', error);
        }
      }

      // Criar resultado completo
      const result: AudioAnalysisResult = {
        chunk,
        chordDetection,
        quality
      };

      // Chamar callback se registrado
      if (this.onAudioChunkCallback) {
        this.onAudioChunkCallback(result);
      }

      // Atualizar estat√≠sticas
      this.updateStats(performance.now() - startTime);

    } catch (error) {
      console.error('Erro no processamento de √°udio:', error);
      this.stats.droppedFrames++;
    }
  }

  /**
   * Processa um chunk de √°udio
   */
  private processAudioChunk(inputBuffer: Float32Array): ProcessedAudioChunk {
    // Copiar dados para buffer circular
    for (let i = 0; i < inputBuffer.length; i++) {
      this.circularBuffer[this.bufferIndex] = inputBuffer[i];
      this.bufferIndex = (this.bufferIndex + 1) % this.circularBuffer.length;
    }

    // Extrair chunk atual do buffer circular (√∫ltimos bufferSize samples)
    const chunkStart = (this.bufferIndex - this.config.bufferSize + this.circularBuffer.length) % this.circularBuffer.length;
    const audioData = new Float32Array(this.config.bufferSize);

    for (let i = 0; i < this.config.bufferSize; i++) {
      audioData[i] = this.circularBuffer[(chunkStart + i) % this.circularBuffer.length];
    }
    
    // Manter hist√≥rico de chunks recentes para an√°lise acumulada
    this.recentChunks.push(new Float32Array(audioData));
    if (this.recentChunks.length > this.maxRecentChunks) {
      this.recentChunks.shift();
    }

    // Calcular m√©tricas b√°sicas
    const rms = this.calculateRMS(audioData);
    const peak = this.calculatePeak(audioData);
    const isSilent = rms < 0.005; // Threshold de sil√™ncio

    return {
      audioData,
      timestamp: Date.now(),
      duration: this.config.bufferSize / this.config.sampleRate,
      rms,
      peak,
      isSilent
    };
  }

  /**
   * Calcula RMS (Root Mean Square) do sinal
   */
  private calculateRMS(buffer: Float32Array): number {
    let sum = 0;
    for (let i = 0; i < buffer.length; i++) {
      sum += buffer[i] * buffer[i];
    }
    return Math.sqrt(sum / buffer.length);
  }

  /**
   * Calcula pico do sinal
   */
  private calculatePeak(buffer: Float32Array): number {
    let peak = 0;
    for (let i = 0; i < buffer.length; i++) {
      peak = Math.max(peak, Math.abs(buffer[i]));
    }
    return peak;
  }

  /**
   * Analisa qualidade do sinal
   */
  private analyzeSignalQuality(chunk: ProcessedAudioChunk): AudioAnalysisResult['quality'] {
    const { audioData } = chunk;

    // Signal-to-Noise Ratio (simplificado)
    const signalPower = chunk.rms * chunk.rms;
    const noisePower = this.estimateNoisePower(audioData);
    const snr = signalPower > 0 ? 10 * Math.log10(signalPower / noisePower) : 0;

    // Clareza (presen√ßa de fundamental vs ru√≠do)
    const clarity = this.calculateSignalClarity(audioData);

    // Estabilidade (consist√™ncia do sinal)
    const stability = this.calculateSignalStability(audioData);

    return {
      signalToNoiseRatio: snr,
      clarity,
      stability
    };
  }

  /**
   * Estima pot√™ncia do ru√≠do
   */
  private estimateNoisePower(audioData: Float32Array): number {
    // M√©todo simplificado: usar amostras com baixa amplitude como ru√≠do
    const noiseSamples: number[] = [];

    for (let i = 0; i < audioData.length; i++) {
      if (Math.abs(audioData[i]) < 0.01) { // Threshold baixo
        noiseSamples.push(audioData[i]);
      }
    }

    if (noiseSamples.length === 0) return 0.0001; // Valor m√≠nimo

    const noisePower = noiseSamples.reduce((sum, sample) => sum + sample * sample, 0) / noiseSamples.length;
    return Math.max(noisePower, 0.0001);
  }

  /**
   * Calcula clareza do sinal (fundamental vs harm√¥nicos/ru√≠do)
   */
  private calculateSignalClarity(audioData: Float32Array): number {
    // Implementa√ß√£o simplificada
    // Em produ√ß√£o, seria baseada em an√°lise espectral

    // Calcular energia total
    const totalEnergy = audioData.reduce((sum, sample) => sum + sample * sample, 0);

    if (totalEnergy === 0) return 0;

    // Estimar energia do fundamental (usando autocorrela√ß√£o)
    const fundamentalEnergy = this.estimateFundamentalEnergy(audioData);

    return Math.min(fundamentalEnergy / totalEnergy, 1);
  }

  /**
   * Estima energia do fundamental
   */
  private estimateFundamentalEnergy(audioData: Float32Array): number {
    // Autocorrela√ß√£o simplificada para encontrar pico
    const sampleRate = this.config.sampleRate;
    const minFreq = 80;
    const maxFreq = 1000;

    const minPeriod = Math.floor(sampleRate / maxFreq);
    const maxPeriod = Math.floor(sampleRate / minFreq);

    let maxCorrelation = 0;

    for (let period = minPeriod; period <= maxPeriod; period++) {
      let correlation = 0;

      for (let i = 0; i < audioData.length - period; i++) {
        correlation += audioData[i] * audioData[i + period];
      }

      maxCorrelation = Math.max(maxCorrelation, correlation);
    }

    return maxCorrelation / audioData.length;
  }

  /**
   * Calcula estabilidade do sinal
   */
  private calculateSignalStability(audioData: Float32Array): number {
    // Medir variabilidade da amplitude ao longo do tempo
    const windowSize = Math.floor(audioData.length / 10);
    const windows: number[] = [];

    for (let i = 0; i < audioData.length; i += windowSize) {
      const window = audioData.slice(i, i + windowSize);
      const rms = this.calculateRMS(window);
      windows.push(rms);
    }

    if (windows.length < 2) return 1;

    // Calcular coeficiente de varia√ß√£o
    const mean = windows.reduce((a, b) => a + b, 0) / windows.length;
    const variance = windows.reduce((sum, rms) => sum + Math.pow(rms - mean, 2), 0) / windows.length;
    const cv = mean > 0 ? Math.sqrt(variance) / mean : 0;

    // Estabilidade = 1 - coeficiente de varia√ß√£o (normalizado)
    return Math.max(0, 1 - cv * 2);
  }

  /**
   * Obt√©m buffer acumulado dos √∫ltimos chunks (para melhor an√°lise)
   */
  private getAccumulatedBuffer(): Float32Array {
    if (this.recentChunks.length === 0) {
      return new Float32Array(this.config.bufferSize);
    }
    
    const totalLength = this.recentChunks.reduce((sum, chunk) => sum + chunk.length, 0);
    const accumulated = new Float32Array(totalLength);
    
    let offset = 0;
    for (const chunk of this.recentChunks) {
      accumulated.set(chunk, offset);
      offset += chunk.length;
    }
    
    return accumulated;
  }

  /**
   * Atualiza estat√≠sticas de processamento
   */
  private updateStats(processingTime: number): void {
    this.stats.chunksProcessed++;
    this.stats.lastProcessingTime = processingTime;

    // Calcular m√©dia m√≥vel da lat√™ncia
    const alpha = 0.1; // Fator de suaviza√ß√£o
    this.stats.averageLatency = alpha * processingTime + (1 - alpha) * this.stats.averageLatency;
  }

  /**
   * Reseta estat√≠sticas
   */
  private resetStats(): void {
    this.stats = {
      chunksProcessed: 0,
      averageLatency: 0,
      droppedFrames: 0,
      lastProcessingTime: 0
    };
  }

  /**
   * Obt√©m estat√≠sticas de performance
   */
  getPerformanceStats(): {
    isInitialized: boolean;
    isProcessing: boolean;
    chunksProcessed: number;
    averageLatency: number;
    droppedFrames: number;
    sampleRate: number;
    bufferSize: number;
    aiServiceStats: any;
  } {
    return {
      isInitialized: this.isInitialized,
      isProcessing: this.isProcessing,
      chunksProcessed: this.stats.chunksProcessed,
      averageLatency: this.stats.averageLatency,
      droppedFrames: this.stats.droppedFrames,
      sampleRate: this.config.sampleRate,
      bufferSize: this.config.bufferSize,
      aiServiceStats: chordDetectionAIService.getPerformanceStats()
    };
  }

  /**
   * Atualiza configura√ß√µes
   */
  updateConfig(config: Partial<AudioProcessingConfig>): void {
    const wasProcessing = this.isProcessing;

    if (wasProcessing) {
      this.stopProcessing();
    }

    this.config = { ...this.config, ...config };

    // Recriar buffers com novo tamanho
    this.audioBuffer = new Float32Array(this.config.bufferSize);
    this.circularBuffer = new Float32Array(this.config.bufferSize * 4);
    this.bufferIndex = 0;

    if (wasProcessing) {
      // Reinicializar com novas configura√ß√µes
      this.dispose();
      this.initialize(this.config).then(success => {
        if (success && this.onAudioChunkCallback) {
          this.startProcessing(this.onAudioChunkCallback);
        }
      });
    }
  }

  /**
   * Limpa recursos
   */
  dispose(): void {
    this.stopProcessing();

    if (this.processor) {
      this.processor.disconnect();
      this.processor = null;
    }

    if (this.analyser) {
      this.analyser.disconnect();
      this.analyser = null;
    }

    if (this.microphone) {
      this.microphone.disconnect();
      this.microphone = null;
    }

    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }

    if (this.stream) {
      this.stream.getTracks().forEach(track => track.stop());
      this.stream = null;
    }

    this.isInitialized = false;
    chordDetectionAIService.dispose();
  }
}

export const audioProcessingService = AudioProcessingService.getInstance();